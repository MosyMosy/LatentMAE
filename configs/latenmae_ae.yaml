
# seed_everything: null
trainer:
  accelerator: 'gpu'
  devices: [2, 3]
  strategy: 'DDP'
  log_every_n_steps: 10
  max_epochs: 500
  precision: 16

  callbacks:
  - class_path: ModelCheckpoint
    init_args:
      monitor: val_loss
      dirpath: 'lightning_logs/checkpoints/LatentMAE_AE/v_frozen_ae/' #set the version of the model
      filename: LatentMAE_{epoch:02d}_{step:02d}_{val_loss:.4f}
      save_top_k: 3
      mode: "min"

  logger:
  - class_path: TensorBoardLogger
    init_args:
      save_dir: lightning_logs/tb_logs
      name: LatentMAE_AE
      version: 'v_frozen_ae' #set the version of the model
  - class_path: CSVLogger
    init_args:
      save_dir: lightning_logs/csv_logs
      name: LatentMAE_AE
      version: 'v_frozen_ae' #set the version of the model


data:
  root_dir: "/export/livia/home/vision/Myazdanpanah/dataset/t-less"
  batch_size: 3
  num_workers: 8

model:
  latent_patch_size: 14
  latent_channel: 4
  mae_patch_size: 16
  mae_channel: 3
  pretrained_path: "pretrained_ckpts/mae_pretrain_vit_base_full.pth"
  mae_backbone: "mae_vit_base_patch16"
  mae_norm_pix_loss: True
  base_batch_size: 256
  use_initial_pretrained: True
  AE_pretrained_path: pretrained_ckpts/autoencoder_kl-f8.ckpt
